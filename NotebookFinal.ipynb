{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Reshape, Activation, Dropout\n",
    "from keras.layers import Concatenate, Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "os.chdir('code')\n",
    "from utils import tf_haversine,get_clusters\n",
    "from data import load_data\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benmosbahmohamed/KerasSolution/DeepLeraning_PredictionTaxi/code/utils.py:83: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  clusters = clusters.as_matrix()\n"
     ]
    }
   ],
   "source": [
    "clusters = get_clusters(data.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation, Dropout,Input\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import Concatenate,Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from utils import tf_haversine\n",
    "from data import load_data\n",
    "from utils import get_clusters\n",
    "from keras.layers import concatenate\n",
    "\n",
    "\n",
    "\n",
    "def start_new_session():\n",
    "    \"\"\"\n",
    "    Starts a new Tensorflow session.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure the session only uses the GPU memory that it actually needs\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    session = tf.Session(config=config, graph=tf.get_default_graph())\n",
    "    K.tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "def first_last_k(coords):\n",
    "    \"\"\"\n",
    "    Returns a list with the first k and last k GPS coordinates from the given trip.\n",
    "    The returned list contains 4k values (latitudes and longitudes for 2k points).\n",
    "    \"\"\"\n",
    "    k = 5\n",
    "    partial = [coords[0] for i in range(2*k)]\n",
    "    num_coords = len(coords)\n",
    "    if num_coords < 2*k:\n",
    "        partial[-num_coords:] = coords\n",
    "    else:\n",
    "        partial[:k] = coords[:k]\n",
    "        partial[-k:] = coords[-k:]\n",
    "    partial = np.row_stack(partial)\n",
    "    return np.array(partial).flatten()\n",
    "\n",
    "\n",
    "def process_features(df):\n",
    "    \"\"\"\n",
    "    Process the features required by our model from the given dataframe.\n",
    "    Return the features in a list so that they can be merged in our model's input layer.\n",
    "    \"\"\"\n",
    "    # Fetch the first and last GPS coordinates\n",
    "    coords = np.row_stack(df['POLYLINE'].apply(first_last_k))\n",
    "    # Standardize latitudes (odd columns) and longitudes (even columns)\n",
    "    latitudes = coords[:,::2]\n",
    "    coords[:,::2] = scale(latitudes)\n",
    "    longitudes = coords[:,1::2]\n",
    "    coords[:,1::2] = scale(longitudes)\n",
    "    \n",
    "    return [\n",
    "        df['QUARTER_HOUR'].as_matrix(),\n",
    "        df['DAY_OF_WEEK'].as_matrix(),\n",
    "        df['WEEK_OF_YEAR'].as_matrix(),\n",
    "        df['ORIGIN_CALL_ENCODED'].as_matrix(),\n",
    "        df['TAXI_ID_ENCODED'].as_matrix(),\n",
    "        df['ORIGIN_STAND_ENCODED'].as_matrix(),\n",
    "        coords,\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_model(metadata, clusters):\n",
    "    \"\"\"\n",
    "    Creates all the layers for our neural network model.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Arbitrary dimension for all embeddings\n",
    "    embedding_dim = 10\n",
    "\n",
    "    # Quarter hour of the day embedding\n",
    "    input_quarter_hour = Input(shape=(1,))\n",
    "    embed_quarter_hour = Embedding(metadata['n_quarter_hours'], embedding_dim, input_length=1)(input_quarter_hour)\n",
    "    embed_quarter_hour = Reshape((embedding_dim,))(embed_quarter_hour)\n",
    "\n",
    "    # Day of the week embedding\n",
    "    input_day_of_week = Input(shape=(1,))\n",
    "    embed_day_of_week = Embedding(metadata['n_days_per_week'], embedding_dim, input_length=1)(input_day_of_week)\n",
    "    embed_day_of_week = Reshape((embedding_dim,))(embed_day_of_week)\n",
    "\n",
    "    # Week of the year embedding\n",
    "    input_week_of_year = Input(shape=(1,))\n",
    "    embed_week_of_year = Embedding(metadata['n_weeks_per_year'], embedding_dim, input_length=1)(input_week_of_year)\n",
    "    embed_week_of_year = Reshape((embedding_dim,))(embed_week_of_year)\n",
    "\n",
    "    # Client ID embedding\n",
    "    input_client_ids = Input(shape=(1,))\n",
    "    embed_client_ids = Embedding(metadata['n_client_ids'], embedding_dim, input_length=1)(input_client_ids)\n",
    "    embed_client_ids = Reshape((embedding_dim,))(embed_client_ids)\n",
    "\n",
    "\n",
    "    # Taxi ID embedding\n",
    "    input_taxi_ids = Input(shape=(1,))\n",
    "    embed_taxi_ids = Embedding(metadata['n_taxi_ids'], embedding_dim, input_length=1)(input_taxi_ids)\n",
    "    embed_taxi_ids = Reshape((embedding_dim,))(embed_taxi_ids)\n",
    "\n",
    "\n",
    "    # Taxi stand ID embedding\n",
    "    input_stand_ids = Input(shape=(1,))\n",
    "    embed_stand_ids = Embedding(metadata['n_stand_ids'], embedding_dim, input_length=1)(input_stand_ids)\n",
    "    embed_stand_ids = Reshape((embedding_dim,))(embed_stand_ids)\n",
    "    \n",
    "    # GPS coordinates (5 first lat/long and 5 latest lat/long, therefore 20 values)\n",
    "\n",
    "    coords_in = Input(shape=(20,))\n",
    "    \n",
    "    #model = Sequential()\n",
    "    \n",
    "    concatenated = concatenate([\n",
    "                embed_quarter_hour,\n",
    "                embed_day_of_week,\n",
    "                embed_week_of_year,\n",
    "                embed_client_ids,\n",
    "                embed_taxi_ids,\n",
    "                embed_stand_ids,\n",
    "                coords_in\n",
    "            ])\n",
    "    \n",
    "    out = Dense(500, activation='relu')(concatenated)\n",
    "    \n",
    "    out = Dense(len(clusters),activation='softmax',name='output_layer')(out)\n",
    "    \n",
    "    cast_clusters = K.cast_to_floatx(clusters)\n",
    "    def destination(probabilities):\n",
    "        return tf.matmul(probabilities, cast_clusters)\n",
    "    \n",
    "    out = Activation(destination)(out)\n",
    "    \n",
    "    model = Model([\n",
    "                input_quarter_hour,\n",
    "                input_day_of_week,\n",
    "                input_week_of_year,\n",
    "                input_client_ids,\n",
    "                input_taxi_ids,\n",
    "                input_stand_ids,\n",
    "                coords_in\n",
    "            ],out)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = SGD(lr=0.01, momentum=0.9, clipvalue=1.)  # Use `clipvalue` to prevent exploding gradients\n",
    "    model.compile(loss=tf_haversine, optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def full_train(data,clusters,n_epochs=100, batch_size=200, save_prefix=None):\n",
    "    \"\"\"\n",
    "    Runs the complete training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load initial data\n",
    "    print(\"Loading data...\")\n",
    "    #data = load_data()\n",
    "    data = data\n",
    "    \n",
    "    # Estimate the GPS clusters\n",
    "    print(\"Estimating clusters...\")\n",
    "    #clusters = get_clusters(data.train_labels)\n",
    "    clusters = clusters\n",
    "    \n",
    "    # Set up callbacks\n",
    "    callbacks = []\n",
    "    if save_prefix is not None:\n",
    "        # Save the model's intermediary weights to disk after each epoch\n",
    "        file_path=\"cache/%s-{epoch:03d}-{val_loss:.4f}.hdf5\" % save_prefix\n",
    "        callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', mode='min', save_weights_only=True, verbose=1))\n",
    "\n",
    "    # Create model\n",
    "    print(\"Creating model...\")\n",
    "    start_new_session()\n",
    "    model = create_model(data.metadata, clusters)\n",
    "    \n",
    "    # Run the training\n",
    "    print(\"Start training...\")\n",
    "    history = model.fit(\n",
    "        process_features(data.train), data.train_labels,\n",
    "        nb_epoch=n_epochs, batch_size=batch_size,\n",
    "        validation_data=(process_features(data.validation), data.validation_labels),\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    if save_prefix is not None:\n",
    "        # Save the training history to disk\n",
    "        file_path = 'cache/%s-history.pickle' % save_prefix\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Estimating clusters...\n",
      "Creating model...\n",
      "WARNING:tensorflow:From /home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:68: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:64: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:68: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/benmosbahmohamed/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:192: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1611521 samples, validate on 16444 samples\n",
      "Epoch 1/100\n",
      "1611521/1611521 [==============================] - 219s 136us/step - loss: 1.7873 - val_loss: 1.5955\n",
      "\n",
      "Epoch 00001: saving model to cache/TrainedOn10_2_5-001-1.5955.hdf5\n",
      "Epoch 2/100\n",
      "1611521/1611521 [==============================] - 218s 135us/step - loss: 1.5740 - val_loss: 1.5600\n",
      "\n",
      "Epoch 00002: saving model to cache/TrainedOn10_2_5-002-1.5600.hdf5\n",
      "Epoch 3/100\n",
      "1611521/1611521 [==============================] - 219s 136us/step - loss: 1.5488 - val_loss: 1.5515\n",
      "\n",
      "Epoch 00003: saving model to cache/TrainedOn10_2_5-003-1.5515.hdf5\n",
      "Epoch 4/100\n",
      "1611521/1611521 [==============================] - 218s 135us/step - loss: 1.5344 - val_loss: 1.5281\n",
      "\n",
      "Epoch 00004: saving model to cache/TrainedOn10_2_5-004-1.5281.hdf5\n",
      "Epoch 5/100\n",
      "1611521/1611521 [==============================] - 218s 135us/step - loss: 1.5238 - val_loss: 1.5215\n",
      "\n",
      "Epoch 00005: saving model to cache/TrainedOn10_2_5-005-1.5215.hdf5\n",
      "Epoch 6/100\n",
      "1611521/1611521 [==============================] - 217s 135us/step - loss: 1.5149 - val_loss: 1.5165\n",
      "\n",
      "Epoch 00006: saving model to cache/TrainedOn10_2_5-006-1.5165.hdf5\n",
      "Epoch 7/100\n",
      "1611521/1611521 [==============================] - 216s 134us/step - loss: 1.5066 - val_loss: 1.5133\n",
      "\n",
      "Epoch 00007: saving model to cache/TrainedOn10_2_5-007-1.5133.hdf5\n",
      "Epoch 8/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.5009 - val_loss: 1.4965\n",
      "\n",
      "Epoch 00008: saving model to cache/TrainedOn10_2_5-008-1.4965.hdf5\n",
      "Epoch 9/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.4950 - val_loss: 1.4977\n",
      "\n",
      "Epoch 00009: saving model to cache/TrainedOn10_2_5-009-1.4977.hdf5\n",
      "Epoch 10/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.4893 - val_loss: 1.4903\n",
      "\n",
      "Epoch 00010: saving model to cache/TrainedOn10_2_5-010-1.4903.hdf5\n",
      "Epoch 11/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.4836 - val_loss: 1.4874\n",
      "\n",
      "Epoch 00011: saving model to cache/TrainedOn10_2_5-011-1.4874.hdf5\n",
      "Epoch 12/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 1.4781 - val_loss: 1.4837\n",
      "\n",
      "Epoch 00012: saving model to cache/TrainedOn10_2_5-012-1.4837.hdf5\n",
      "Epoch 13/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 1.4731 - val_loss: 1.4825\n",
      "\n",
      "Epoch 00013: saving model to cache/TrainedOn10_2_5-013-1.4825.hdf5\n",
      "Epoch 14/100\n",
      "1611521/1611521 [==============================] - 216s 134us/step - loss: 1.4688 - val_loss: 1.4850\n",
      "\n",
      "Epoch 00014: saving model to cache/TrainedOn10_2_5-014-1.4850.hdf5\n",
      "Epoch 15/100\n",
      "1611521/1611521 [==============================] - 216s 134us/step - loss: 1.4642 - val_loss: 1.4894\n",
      "\n",
      "Epoch 00015: saving model to cache/TrainedOn10_2_5-015-1.4894.hdf5\n",
      "Epoch 16/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.4602 - val_loss: 1.4901\n",
      "\n",
      "Epoch 00016: saving model to cache/TrainedOn10_2_5-016-1.4901.hdf5\n",
      "Epoch 17/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 1.4555 - val_loss: 1.4720\n",
      "\n",
      "Epoch 00017: saving model to cache/TrainedOn10_2_5-017-1.4720.hdf5\n",
      "Epoch 18/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.9402 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00018: saving model to cache/TrainedOn10_2_5-018-0.0000.hdf5\n",
      "Epoch 19/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00019: saving model to cache/TrainedOn10_2_5-019-0.0000.hdf5\n",
      "Epoch 20/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00020: saving model to cache/TrainedOn10_2_5-020-0.0000.hdf5\n",
      "Epoch 21/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00021: saving model to cache/TrainedOn10_2_5-021-0.0000.hdf5\n",
      "Epoch 22/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00022: saving model to cache/TrainedOn10_2_5-022-0.0000.hdf5\n",
      "Epoch 23/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00023: saving model to cache/TrainedOn10_2_5-023-0.0000.hdf5\n",
      "Epoch 24/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00024: saving model to cache/TrainedOn10_2_5-024-0.0000.hdf5\n",
      "Epoch 25/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00025: saving model to cache/TrainedOn10_2_5-025-0.0000.hdf5\n",
      "Epoch 26/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00026: saving model to cache/TrainedOn10_2_5-026-0.0000.hdf5\n",
      "Epoch 27/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00027: saving model to cache/TrainedOn10_2_5-027-0.0000.hdf5\n",
      "Epoch 28/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00028: saving model to cache/TrainedOn10_2_5-028-0.0000.hdf5\n",
      "Epoch 29/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00029: saving model to cache/TrainedOn10_2_5-029-0.0000.hdf5\n",
      "Epoch 30/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00030: saving model to cache/TrainedOn10_2_5-030-0.0000.hdf5\n",
      "Epoch 31/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00031: saving model to cache/TrainedOn10_2_5-031-0.0000.hdf5\n",
      "Epoch 32/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00032: saving model to cache/TrainedOn10_2_5-032-0.0000.hdf5\n",
      "Epoch 33/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00033: saving model to cache/TrainedOn10_2_5-033-0.0000.hdf5\n",
      "Epoch 34/100\n",
      "1611521/1611521 [==============================] - 215s 133us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00034: saving model to cache/TrainedOn10_2_5-034-0.0000.hdf5\n",
      "Epoch 35/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00035: saving model to cache/TrainedOn10_2_5-035-0.0000.hdf5\n",
      "Epoch 36/100\n",
      "1611521/1611521 [==============================] - 215s 134us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00036: saving model to cache/TrainedOn10_2_5-036-0.0000.hdf5\n",
      "Epoch 37/100\n",
      "1611521/1611521 [==============================] - 230s 143us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00037: saving model to cache/TrainedOn10_2_5-037-0.0000.hdf5\n",
      "Epoch 38/100\n",
      "1611521/1611521 [==============================] - 218s 135us/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "\n",
      "Epoch 00038: saving model to cache/TrainedOn10_2_5-038-0.0000.hdf5\n",
      "Epoch 39/100\n",
      " 301000/1611521 [====>.........................] - ETA: 2:54 - loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34ca917e9f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_haversine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TrainedOn10_2_5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-21b1cdbc8b52>\u001b[0m in \u001b[0;36mfull_train\u001b[0;34m(data, clusters, n_epochs, batch_size, save_prefix)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_prefix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir('code')\n",
    "from utils import tf_haversine,get_clusters\n",
    "os.chdir('..')\n",
    "history = full_train(data,clusters,save_prefix='TrainedOn10_2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndReL2J0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22721dd8978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je regarde à quel point il est bon\n",
    "#Je load les weights du modèle pas la peine de réentraîner hehe\n",
    "start_new_session()\n",
    "model = create_model(data.metadata, clusters)\n",
    "#c'est là que je load les weights\n",
    "model.load_weights('cache\\TrainedOn10_2_5-100-1.5631.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Les prédictions sur l'ensemble de test de la compet (tout petit)\n",
    "test_predictions = model.predict(process_features(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4601464225973106"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('code')\n",
    "from utils import np_haversine\n",
    "os.chdir('..')\n",
    "np_haversine(test_predictions, data.test_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En s'entraînant que sur le dixième des données, on obtient une loss de 1.46 (km) sur le truc de test. C'est mieux que sur le blog... Soit j'ai mal copié un truc qui fait que ça marche mieux hahah, soit keras 2.x et meilleur que 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
