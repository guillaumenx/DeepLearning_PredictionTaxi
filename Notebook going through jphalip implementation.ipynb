{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Reshape, Activation, Dropout\n",
    "from keras.layers import Concatenate, Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "os.chdir('code')\n",
    "from utils import tf_haversine,get_clusters\n",
    "from data import load_data\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data(nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = get_clusters(data.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Activation, Dropout,Input\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import Concatenate,Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from utils import tf_haversine\n",
    "from data import load_data\n",
    "from utils import get_clusters\n",
    "from keras.layers import concatenate\n",
    "\n",
    "\n",
    "\n",
    "def start_new_session():\n",
    "    \"\"\"\n",
    "    Starts a new Tensorflow session.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make sure the session only uses the GPU memory that it actually needs\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    session = tf.Session(config=config, graph=tf.get_default_graph())\n",
    "    K.tensorflow_backend.set_session(session)\n",
    "\n",
    "\n",
    "def first_last_k(coords):\n",
    "    \"\"\"\n",
    "    Returns a list with the first k and last k GPS coordinates from the given trip.\n",
    "    The returned list contains 4k values (latitudes and longitudes for 2k points).\n",
    "    \"\"\"\n",
    "    k = 5\n",
    "    partial = [coords[0] for i in range(2*k)]\n",
    "    num_coords = len(coords)\n",
    "    if num_coords < 2*k:\n",
    "        partial[-num_coords:] = coords\n",
    "    else:\n",
    "        partial[:k] = coords[:k]\n",
    "        partial[-k:] = coords[-k:]\n",
    "    partial = np.row_stack(partial)\n",
    "    return np.array(partial).flatten()\n",
    "\n",
    "\n",
    "def process_features(df):\n",
    "    \"\"\"\n",
    "    Process the features required by our model from the given dataframe.\n",
    "    Return the features in a list so that they can be merged in our model's input layer.\n",
    "    \"\"\"\n",
    "    # Fetch the first and last GPS coordinates\n",
    "    coords = np.row_stack(df['POLYLINE'].apply(first_last_k))\n",
    "    # Standardize latitudes (odd columns) and longitudes (even columns)\n",
    "    latitudes = coords[:,::2]\n",
    "    coords[:,::2] = scale(latitudes)\n",
    "    longitudes = coords[:,1::2]\n",
    "    coords[:,1::2] = scale(longitudes)\n",
    "    \n",
    "    return [\n",
    "        df['QUARTER_HOUR'].as_matrix(),\n",
    "        df['DAY_OF_WEEK'].as_matrix(),\n",
    "        df['WEEK_OF_YEAR'].as_matrix(),\n",
    "        df['ORIGIN_CALL_ENCODED'].as_matrix(),\n",
    "        df['TAXI_ID_ENCODED'].as_matrix(),\n",
    "        df['ORIGIN_STAND_ENCODED'].as_matrix(),\n",
    "        coords,\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_model(metadata, clusters):\n",
    "    \"\"\"\n",
    "    Creates all the layers for our neural network model.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Arbitrary dimension for all embeddings\n",
    "    embedding_dim = 10\n",
    "\n",
    "    # Quarter hour of the day embedding\n",
    "    input_quarter_hour = Input(shape=(1,))\n",
    "    embed_quarter_hour = Embedding(metadata['n_quarter_hours'], embedding_dim, input_length=1)(input_quarter_hour)\n",
    "    embed_quarter_hour = Reshape((embedding_dim,))(embed_quarter_hour)\n",
    "\n",
    "    # Day of the week embedding\n",
    "    input_day_of_week = Input(shape=(1,))\n",
    "    embed_day_of_week = Embedding(metadata['n_days_per_week'], embedding_dim, input_length=1)(input_day_of_week)\n",
    "    embed_day_of_week = Reshape((embedding_dim,))(embed_day_of_week)\n",
    "\n",
    "    # Week of the year embedding\n",
    "    input_week_of_year = Input(shape=(1,))\n",
    "    embed_week_of_year = Embedding(metadata['n_weeks_per_year'], embedding_dim, input_length=1)(input_week_of_year)\n",
    "    embed_week_of_year = Reshape((embedding_dim,))(embed_week_of_year)\n",
    "\n",
    "    # Client ID embedding\n",
    "    input_client_ids = Input(shape=(1,))\n",
    "    embed_client_ids = Embedding(metadata['n_client_ids'], embedding_dim, input_length=1)(input_client_ids)\n",
    "    embed_client_ids = Reshape((embedding_dim,))(embed_client_ids)\n",
    "\n",
    "\n",
    "    # Taxi ID embedding\n",
    "    input_taxi_ids = Input(shape=(1,))\n",
    "    embed_taxi_ids = Embedding(metadata['n_taxi_ids'], embedding_dim, input_length=1)(input_taxi_ids)\n",
    "    embed_taxi_ids = Reshape((embedding_dim,))(embed_taxi_ids)\n",
    "\n",
    "\n",
    "    # Taxi stand ID embedding\n",
    "    input_stand_ids = Input(shape=(1,))\n",
    "    embed_stand_ids = Embedding(metadata['n_stand_ids'], embedding_dim, input_length=1)(input_stand_ids)\n",
    "    embed_stand_ids = Reshape((embedding_dim,))(embed_stand_ids)\n",
    "    \n",
    "    # GPS coordinates (5 first lat/long and 5 latest lat/long, therefore 20 values)\n",
    "\n",
    "    coords_in = Input(shape=(20,))\n",
    "    \n",
    "    #model = Sequential()\n",
    "    \n",
    "    concatenated = concatenate([\n",
    "                embed_quarter_hour,\n",
    "                embed_day_of_week,\n",
    "                embed_week_of_year,\n",
    "                embed_client_ids,\n",
    "                embed_taxi_ids,\n",
    "                embed_stand_ids,\n",
    "                coords_in\n",
    "            ])\n",
    "    \n",
    "    out = Dense(500, activation='relu')(concatenated)\n",
    "    \n",
    "    out = Dense(len(clusters),activation='softmax',name='output_layer')(out)\n",
    "    \n",
    "    cast_clusters = K.cast_to_floatx(clusters)\n",
    "    def destination(probabilities):\n",
    "        return tf.matmul(probabilities, cast_clusters)\n",
    "    \n",
    "    out = Activation(destination)(out)\n",
    "    \n",
    "    model = Model([\n",
    "                input_quarter_hour,\n",
    "                input_day_of_week,\n",
    "                input_week_of_year,\n",
    "                input_client_ids,\n",
    "                input_taxi_ids,\n",
    "                input_stand_ids,\n",
    "                coords_in\n",
    "            ],out)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = SGD(lr=0.01, momentum=0.9, clipvalue=1.)  # Use `clipvalue` to prevent exploding gradients\n",
    "    model.compile(loss=tf_haversine, optimizer=optimizer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def full_train(data,clusters,n_epochs=100, batch_size=200, save_prefix=None):\n",
    "    \"\"\"\n",
    "    Runs the complete training process.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load initial data\n",
    "    print(\"Loading data...\")\n",
    "    #data = load_data()\n",
    "    data = data\n",
    "    \n",
    "    # Estimate the GPS clusters\n",
    "    print(\"Estimating clusters...\")\n",
    "    #clusters = get_clusters(data.train_labels)\n",
    "    clusters = clusters\n",
    "    \n",
    "    # Set up callbacks\n",
    "    callbacks = []\n",
    "    if save_prefix is not None:\n",
    "        # Save the model's intermediary weights to disk after each epoch\n",
    "        file_path=\"cache/%s-{epoch:03d}-{val_loss:.4f}.hdf5\" % save_prefix\n",
    "        callbacks.append(ModelCheckpoint(file_path, monitor='val_loss', mode='min', save_weights_only=True, verbose=1))\n",
    "\n",
    "    # Create model\n",
    "    print(\"Creating model...\")\n",
    "    start_new_session()\n",
    "    model = create_model(data.metadata, clusters)\n",
    "    \n",
    "    # Run the training\n",
    "    print(\"Start training...\")\n",
    "    history = model.fit(\n",
    "        process_features(data.train), data.train_labels,\n",
    "        nb_epoch=n_epochs, batch_size=batch_size,\n",
    "        validation_data=(process_features(data.validation), data.validation_labels),\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    if save_prefix is not None:\n",
    "        # Save the training history to disk\n",
    "        file_path = 'cache/%s-history.pickle' % save_prefix\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Estimating clusters...\n",
      "Creating model...\n",
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:192: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94831 samples, validate on 968 samples\n",
      "Epoch 1/100\n",
      "94831/94831 [==============================] - 58s 611us/step - loss: 3.0194 - val_loss: 2.5661\n",
      "\n",
      "Epoch 00001: saving model to cache/TrainedOn10_2_5-001-2.5661.hdf5\n",
      "Epoch 2/100\n",
      "94831/94831 [==============================] - 55s 580us/step - loss: 2.1989 - val_loss: 2.0202\n",
      "\n",
      "Epoch 00002: saving model to cache/TrainedOn10_2_5-002-2.0202.hdf5\n",
      "Epoch 3/100\n",
      "94831/94831 [==============================] - 57s 602us/step - loss: 1.9210 - val_loss: 1.8009\n",
      "\n",
      "Epoch 00003: saving model to cache/TrainedOn10_2_5-003-1.8009.hdf5\n",
      "Epoch 4/100\n",
      "94831/94831 [==============================] - 56s 592us/step - loss: 1.8209 - val_loss: 1.7428\n",
      "\n",
      "Epoch 00004: saving model to cache/TrainedOn10_2_5-004-1.7428.hdf5\n",
      "Epoch 5/100\n",
      "94831/94831 [==============================] - 63s 666us/step - loss: 1.7854 - val_loss: 1.7285\n",
      "\n",
      "Epoch 00005: saving model to cache/TrainedOn10_2_5-005-1.7285.hdf5\n",
      "Epoch 6/100\n",
      "94831/94831 [==============================] - 66s 695us/step - loss: 1.7637 - val_loss: 1.7037\n",
      "\n",
      "Epoch 00006: saving model to cache/TrainedOn10_2_5-006-1.7037.hdf5\n",
      "Epoch 7/100\n",
      "94831/94831 [==============================] - 64s 680us/step - loss: 1.7382 - val_loss: 1.6957\n",
      "\n",
      "Epoch 00007: saving model to cache/TrainedOn10_2_5-007-1.6957.hdf5\n",
      "Epoch 8/100\n",
      "94831/94831 [==============================] - 64s 677us/step - loss: 1.7109 - val_loss: 1.6520\n",
      "\n",
      "Epoch 00008: saving model to cache/TrainedOn10_2_5-008-1.6520.hdf5\n",
      "Epoch 9/100\n",
      "94831/94831 [==============================] - 60s 632us/step - loss: 1.6825 - val_loss: 1.6213\n",
      "\n",
      "Epoch 00009: saving model to cache/TrainedOn10_2_5-009-1.6213.hdf5\n",
      "Epoch 10/100\n",
      "94831/94831 [==============================] - 61s 648us/step - loss: 1.6613 - val_loss: 1.6087\n",
      "\n",
      "Epoch 00010: saving model to cache/TrainedOn10_2_5-010-1.6087.hdf5\n",
      "Epoch 11/100\n",
      "94831/94831 [==============================] - 61s 647us/step - loss: 1.6447 - val_loss: 1.6037\n",
      "\n",
      "Epoch 00011: saving model to cache/TrainedOn10_2_5-011-1.6037.hdf5\n",
      "Epoch 12/100\n",
      "94831/94831 [==============================] - 66s 693us/step - loss: 1.6361 - val_loss: 1.6132\n",
      "\n",
      "Epoch 00012: saving model to cache/TrainedOn10_2_5-012-1.6132.hdf5\n",
      "Epoch 13/100\n",
      "94831/94831 [==============================] - 65s 685us/step - loss: 1.6296 - val_loss: 1.6013\n",
      "\n",
      "Epoch 00013: saving model to cache/TrainedOn10_2_5-013-1.6013.hdf5\n",
      "Epoch 14/100\n",
      "94831/94831 [==============================] - 61s 640us/step - loss: 1.6234 - val_loss: 1.5867\n",
      "\n",
      "Epoch 00014: saving model to cache/TrainedOn10_2_5-014-1.5867.hdf5\n",
      "Epoch 15/100\n",
      "94831/94831 [==============================] - 65s 681us/step - loss: 1.6160 - val_loss: 1.5742\n",
      "\n",
      "Epoch 00015: saving model to cache/TrainedOn10_2_5-015-1.5742.hdf5\n",
      "Epoch 16/100\n",
      "94831/94831 [==============================] - 61s 645us/step - loss: 1.6122 - val_loss: 1.5706\n",
      "\n",
      "Epoch 00016: saving model to cache/TrainedOn10_2_5-016-1.5706.hdf5\n",
      "Epoch 17/100\n",
      "94831/94831 [==============================] - 64s 677us/step - loss: 1.6077 - val_loss: 1.5640\n",
      "\n",
      "Epoch 00017: saving model to cache/TrainedOn10_2_5-017-1.5640.hdf5\n",
      "Epoch 18/100\n",
      "94831/94831 [==============================] - 59s 624us/step - loss: 1.6040 - val_loss: 1.5561\n",
      "\n",
      "Epoch 00018: saving model to cache/TrainedOn10_2_5-018-1.5561.hdf5\n",
      "Epoch 19/100\n",
      "94831/94831 [==============================] - 55s 582us/step - loss: 1.5995 - val_loss: 1.5569\n",
      "\n",
      "Epoch 00019: saving model to cache/TrainedOn10_2_5-019-1.5569.hdf5\n",
      "Epoch 20/100\n",
      "94831/94831 [==============================] - 55s 582us/step - loss: 1.5974 - val_loss: 1.5529\n",
      "\n",
      "Epoch 00020: saving model to cache/TrainedOn10_2_5-020-1.5529.hdf5\n",
      "Epoch 21/100\n",
      "94831/94831 [==============================] - 55s 579us/step - loss: 1.5962 - val_loss: 1.5457\n",
      "\n",
      "Epoch 00021: saving model to cache/TrainedOn10_2_5-021-1.5457.hdf5\n",
      "Epoch 22/100\n",
      "94831/94831 [==============================] - 54s 571us/step - loss: 1.5911 - val_loss: 1.5420\n",
      "\n",
      "Epoch 00022: saving model to cache/TrainedOn10_2_5-022-1.5420.hdf5\n",
      "Epoch 23/100\n",
      "94831/94831 [==============================] - 54s 565us/step - loss: 1.5875 - val_loss: 1.5625\n",
      "\n",
      "Epoch 00023: saving model to cache/TrainedOn10_2_5-023-1.5625.hdf5\n",
      "Epoch 24/100\n",
      "94831/94831 [==============================] - 54s 572us/step - loss: 1.5872 - val_loss: 1.5696\n",
      "\n",
      "Epoch 00024: saving model to cache/TrainedOn10_2_5-024-1.5696.hdf5\n",
      "Epoch 25/100\n",
      "94831/94831 [==============================] - 54s 567us/step - loss: 1.5827 - val_loss: 1.5675\n",
      "\n",
      "Epoch 00025: saving model to cache/TrainedOn10_2_5-025-1.5675.hdf5\n",
      "Epoch 26/100\n",
      "94831/94831 [==============================] - 54s 570us/step - loss: 1.5835 - val_loss: 1.5523\n",
      "\n",
      "Epoch 00026: saving model to cache/TrainedOn10_2_5-026-1.5523.hdf5\n",
      "Epoch 27/100\n",
      "94831/94831 [==============================] - 57s 606us/step - loss: 1.5799 - val_loss: 1.5663\n",
      "\n",
      "Epoch 00027: saving model to cache/TrainedOn10_2_5-027-1.5663.hdf5\n",
      "Epoch 28/100\n",
      "94831/94831 [==============================] - 63s 660us/step - loss: 1.5784 - val_loss: 1.5636\n",
      "\n",
      "Epoch 00028: saving model to cache/TrainedOn10_2_5-028-1.5636.hdf5\n",
      "Epoch 29/100\n",
      "94831/94831 [==============================] - 59s 627us/step - loss: 1.5737 - val_loss: 1.5604\n",
      "\n",
      "Epoch 00029: saving model to cache/TrainedOn10_2_5-029-1.5604.hdf5\n",
      "Epoch 30/100\n",
      "94831/94831 [==============================] - 63s 669us/step - loss: 1.5720 - val_loss: 1.5561\n",
      "\n",
      "Epoch 00030: saving model to cache/TrainedOn10_2_5-030-1.5561.hdf5\n",
      "Epoch 31/100\n",
      "94831/94831 [==============================] - 70s 734us/step - loss: 1.5713 - val_loss: 1.5642\n",
      "\n",
      "Epoch 00031: saving model to cache/TrainedOn10_2_5-031-1.5642.hdf5\n",
      "Epoch 32/100\n",
      "94831/94831 [==============================] - 63s 662us/step - loss: 1.5695 - val_loss: 1.5408\n",
      "\n",
      "Epoch 00032: saving model to cache/TrainedOn10_2_5-032-1.5408.hdf5\n",
      "Epoch 33/100\n",
      "94831/94831 [==============================] - 60s 635us/step - loss: 1.5673 - val_loss: 1.5515\n",
      "\n",
      "Epoch 00033: saving model to cache/TrainedOn10_2_5-033-1.5515.hdf5\n",
      "Epoch 34/100\n",
      "94831/94831 [==============================] - 59s 619us/step - loss: 1.5653 - val_loss: 1.5484\n",
      "\n",
      "Epoch 00034: saving model to cache/TrainedOn10_2_5-034-1.5484.hdf5\n",
      "Epoch 35/100\n",
      "94831/94831 [==============================] - 66s 696us/step - loss: 1.5637 - val_loss: 1.5221\n",
      "\n",
      "Epoch 00035: saving model to cache/TrainedOn10_2_5-035-1.5221.hdf5\n",
      "Epoch 36/100\n",
      "94831/94831 [==============================] - 60s 633us/step - loss: 1.5636 - val_loss: 1.5505\n",
      "\n",
      "Epoch 00036: saving model to cache/TrainedOn10_2_5-036-1.5505.hdf5\n",
      "Epoch 37/100\n",
      "94831/94831 [==============================] - 57s 603us/step - loss: 1.5626 - val_loss: 1.5493\n",
      "\n",
      "Epoch 00037: saving model to cache/TrainedOn10_2_5-037-1.5493.hdf5\n",
      "Epoch 38/100\n",
      "94831/94831 [==============================] - 62s 657us/step - loss: 1.5609 - val_loss: 1.5461\n",
      "\n",
      "Epoch 00038: saving model to cache/TrainedOn10_2_5-038-1.5461.hdf5\n",
      "Epoch 39/100\n",
      "94831/94831 [==============================] - 56s 590us/step - loss: 1.5580 - val_loss: 1.5457\n",
      "\n",
      "Epoch 00039: saving model to cache/TrainedOn10_2_5-039-1.5457.hdf5\n",
      "Epoch 40/100\n",
      "94831/94831 [==============================] - 60s 629us/step - loss: 1.5580 - val_loss: 1.5529\n",
      "\n",
      "Epoch 00040: saving model to cache/TrainedOn10_2_5-040-1.5529.hdf5\n",
      "Epoch 41/100\n",
      "94831/94831 [==============================] - 61s 640us/step - loss: 1.5554 - val_loss: 1.5430\n",
      "\n",
      "Epoch 00041: saving model to cache/TrainedOn10_2_5-041-1.5430.hdf5\n",
      "Epoch 42/100\n",
      "94831/94831 [==============================] - 60s 631us/step - loss: 1.5544 - val_loss: 1.5695\n",
      "\n",
      "Epoch 00042: saving model to cache/TrainedOn10_2_5-042-1.5695.hdf5\n",
      "Epoch 43/100\n",
      "94831/94831 [==============================] - 60s 629us/step - loss: 1.5520 - val_loss: 1.5388\n",
      "\n",
      "Epoch 00043: saving model to cache/TrainedOn10_2_5-043-1.5388.hdf5\n",
      "Epoch 44/100\n",
      "94831/94831 [==============================] - 86s 903us/step - loss: 1.5489 - val_loss: 1.5318\n",
      "\n",
      "Epoch 00044: saving model to cache/TrainedOn10_2_5-044-1.5318.hdf5\n",
      "Epoch 45/100\n",
      "94831/94831 [==============================] - 56s 589us/step - loss: 1.5483 - val_loss: 1.5293\n",
      "\n",
      "Epoch 00045: saving model to cache/TrainedOn10_2_5-045-1.5293.hdf5\n",
      "Epoch 46/100\n",
      "94831/94831 [==============================] - 58s 607us/step - loss: 1.5473 - val_loss: 1.5566\n",
      "\n",
      "Epoch 00046: saving model to cache/TrainedOn10_2_5-046-1.5566.hdf5\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94831/94831 [==============================] - 54s 571us/step - loss: 1.5456 - val_loss: 1.5538\n",
      "\n",
      "Epoch 00047: saving model to cache/TrainedOn10_2_5-047-1.5538.hdf5\n",
      "Epoch 48/100\n",
      "94831/94831 [==============================] - 54s 572us/step - loss: 1.5432 - val_loss: 1.5367\n",
      "\n",
      "Epoch 00048: saving model to cache/TrainedOn10_2_5-048-1.5367.hdf5\n",
      "Epoch 49/100\n",
      "94831/94831 [==============================] - 54s 569us/step - loss: 1.5426 - val_loss: 1.5376\n",
      "\n",
      "Epoch 00049: saving model to cache/TrainedOn10_2_5-049-1.5376.hdf5\n",
      "Epoch 50/100\n",
      "94831/94831 [==============================] - 55s 578us/step - loss: 1.5395 - val_loss: 1.5549\n",
      "\n",
      "Epoch 00050: saving model to cache/TrainedOn10_2_5-050-1.5549.hdf5\n",
      "Epoch 51/100\n",
      "94831/94831 [==============================] - 56s 589us/step - loss: 1.5381 - val_loss: 1.5399\n",
      "\n",
      "Epoch 00051: saving model to cache/TrainedOn10_2_5-051-1.5399.hdf5\n",
      "Epoch 52/100\n",
      "94831/94831 [==============================] - 57s 605us/step - loss: 1.5372 - val_loss: 1.5499\n",
      "\n",
      "Epoch 00052: saving model to cache/TrainedOn10_2_5-052-1.5499.hdf5\n",
      "Epoch 53/100\n",
      "94831/94831 [==============================] - 57s 602us/step - loss: 1.5358 - val_loss: 1.5634\n",
      "\n",
      "Epoch 00053: saving model to cache/TrainedOn10_2_5-053-1.5634.hdf5\n",
      "Epoch 54/100\n",
      "94831/94831 [==============================] - 57s 597us/step - loss: 1.5348 - val_loss: 1.5589\n",
      "\n",
      "Epoch 00054: saving model to cache/TrainedOn10_2_5-054-1.5589.hdf5\n",
      "Epoch 55/100\n",
      "94831/94831 [==============================] - 59s 624us/step - loss: 1.5319 - val_loss: 1.5400\n",
      "\n",
      "Epoch 00055: saving model to cache/TrainedOn10_2_5-055-1.5400.hdf5\n",
      "Epoch 56/100\n",
      "94831/94831 [==============================] - 61s 641us/step - loss: 1.5291 - val_loss: 1.5314\n",
      "\n",
      "Epoch 00056: saving model to cache/TrainedOn10_2_5-056-1.5314.hdf5\n",
      "Epoch 57/100\n",
      "94831/94831 [==============================] - 57s 606us/step - loss: 1.5294 - val_loss: 1.5317\n",
      "\n",
      "Epoch 00057: saving model to cache/TrainedOn10_2_5-057-1.5317.hdf5\n",
      "Epoch 58/100\n",
      "94831/94831 [==============================] - 60s 627us/step - loss: 1.5251 - val_loss: 1.5376\n",
      "\n",
      "Epoch 00058: saving model to cache/TrainedOn10_2_5-058-1.5376.hdf5\n",
      "Epoch 59/100\n",
      "94831/94831 [==============================] - 56s 590us/step - loss: 1.5222 - val_loss: 1.5574\n",
      "\n",
      "Epoch 00059: saving model to cache/TrainedOn10_2_5-059-1.5574.hdf5\n",
      "Epoch 60/100\n",
      "94831/94831 [==============================] - 54s 574us/step - loss: 1.5258 - val_loss: 1.5610\n",
      "\n",
      "Epoch 00060: saving model to cache/TrainedOn10_2_5-060-1.5610.hdf5\n",
      "Epoch 61/100\n",
      "94831/94831 [==============================] - 54s 570us/step - loss: 1.5184 - val_loss: 1.5247\n",
      "\n",
      "Epoch 00061: saving model to cache/TrainedOn10_2_5-061-1.5247.hdf5\n",
      "Epoch 62/100\n",
      "94831/94831 [==============================] - 57s 598us/step - loss: 1.5160 - val_loss: 1.5511\n",
      "\n",
      "Epoch 00062: saving model to cache/TrainedOn10_2_5-062-1.5511.hdf5\n",
      "Epoch 63/100\n",
      "94831/94831 [==============================] - 83s 879us/step - loss: 1.5144 - val_loss: 1.5429\n",
      "\n",
      "Epoch 00063: saving model to cache/TrainedOn10_2_5-063-1.5429.hdf5\n",
      "Epoch 64/100\n",
      "94831/94831 [==============================] - 62s 654us/step - loss: 1.5137 - val_loss: 1.5564\n",
      "\n",
      "Epoch 00064: saving model to cache/TrainedOn10_2_5-064-1.5564.hdf5\n",
      "Epoch 65/100\n",
      "94831/94831 [==============================] - 60s 636us/step - loss: 1.5113 - val_loss: 1.5532\n",
      "\n",
      "Epoch 00065: saving model to cache/TrainedOn10_2_5-065-1.5532.hdf5\n",
      "Epoch 66/100\n",
      "94831/94831 [==============================] - 67s 704us/step - loss: 1.5073 - val_loss: 1.5783\n",
      "\n",
      "Epoch 00066: saving model to cache/TrainedOn10_2_5-066-1.5783.hdf5\n",
      "Epoch 67/100\n",
      "94831/94831 [==============================] - 59s 620us/step - loss: 1.5053 - val_loss: 1.5568\n",
      "\n",
      "Epoch 00067: saving model to cache/TrainedOn10_2_5-067-1.5568.hdf5\n",
      "Epoch 68/100\n",
      "94831/94831 [==============================] - 59s 620us/step - loss: 1.5014 - val_loss: 1.5471\n",
      "\n",
      "Epoch 00068: saving model to cache/TrainedOn10_2_5-068-1.5471.hdf5\n",
      "Epoch 69/100\n",
      "94831/94831 [==============================] - 59s 621us/step - loss: 1.4999 - val_loss: 1.5474\n",
      "\n",
      "Epoch 00069: saving model to cache/TrainedOn10_2_5-069-1.5474.hdf5\n",
      "Epoch 70/100\n",
      "94831/94831 [==============================] - 58s 606us/step - loss: 1.4960 - val_loss: 1.5401\n",
      "\n",
      "Epoch 00070: saving model to cache/TrainedOn10_2_5-070-1.5401.hdf5\n",
      "Epoch 71/100\n",
      "94831/94831 [==============================] - 55s 577us/step - loss: 1.4920 - val_loss: 1.5594\n",
      "\n",
      "Epoch 00071: saving model to cache/TrainedOn10_2_5-071-1.5594.hdf5\n",
      "Epoch 72/100\n",
      "94831/94831 [==============================] - 55s 581us/step - loss: 1.4916 - val_loss: 1.5525\n",
      "\n",
      "Epoch 00072: saving model to cache/TrainedOn10_2_5-072-1.5525.hdf5\n",
      "Epoch 73/100\n",
      "94831/94831 [==============================] - 55s 577us/step - loss: 1.4868 - val_loss: 1.5579\n",
      "\n",
      "Epoch 00073: saving model to cache/TrainedOn10_2_5-073-1.5579.hdf5\n",
      "Epoch 74/100\n",
      "94831/94831 [==============================] - 55s 576us/step - loss: 1.4875 - val_loss: 1.5421\n",
      "\n",
      "Epoch 00074: saving model to cache/TrainedOn10_2_5-074-1.5421.hdf5\n",
      "Epoch 75/100\n",
      "94831/94831 [==============================] - 54s 574us/step - loss: 1.4818 - val_loss: 1.5846\n",
      "\n",
      "Epoch 00075: saving model to cache/TrainedOn10_2_5-075-1.5846.hdf5\n",
      "Epoch 76/100\n",
      "94831/94831 [==============================] - 55s 583us/step - loss: 1.4810 - val_loss: 1.5678\n",
      "\n",
      "Epoch 00076: saving model to cache/TrainedOn10_2_5-076-1.5678.hdf5\n",
      "Epoch 77/100\n",
      "94831/94831 [==============================] - 54s 575us/step - loss: 1.4784 - val_loss: 1.5791\n",
      "\n",
      "Epoch 00077: saving model to cache/TrainedOn10_2_5-077-1.5791.hdf5\n",
      "Epoch 78/100\n",
      "94831/94831 [==============================] - 56s 592us/step - loss: 1.4746 - val_loss: 1.5939\n",
      "\n",
      "Epoch 00078: saving model to cache/TrainedOn10_2_5-078-1.5939.hdf5\n",
      "Epoch 79/100\n",
      "94831/94831 [==============================] - 54s 570us/step - loss: 1.4722 - val_loss: 1.5510\n",
      "\n",
      "Epoch 00079: saving model to cache/TrainedOn10_2_5-079-1.5510.hdf5\n",
      "Epoch 80/100\n",
      "94831/94831 [==============================] - 54s 569us/step - loss: 1.4700 - val_loss: 1.5532\n",
      "\n",
      "Epoch 00080: saving model to cache/TrainedOn10_2_5-080-1.5532.hdf5\n",
      "Epoch 81/100\n",
      "94831/94831 [==============================] - 62s 651us/step - loss: 1.4637 - val_loss: 1.5931\n",
      "\n",
      "Epoch 00081: saving model to cache/TrainedOn10_2_5-081-1.5931.hdf5\n",
      "Epoch 82/100\n",
      "94831/94831 [==============================] - 72s 756us/step - loss: 1.4636 - val_loss: 1.5391\n",
      "\n",
      "Epoch 00082: saving model to cache/TrainedOn10_2_5-082-1.5391.hdf5\n",
      "Epoch 83/100\n",
      "94831/94831 [==============================] - 55s 578us/step - loss: 1.4581 - val_loss: 1.5747\n",
      "\n",
      "Epoch 00083: saving model to cache/TrainedOn10_2_5-083-1.5747.hdf5\n",
      "Epoch 84/100\n",
      "94831/94831 [==============================] - 54s 572us/step - loss: 1.4582 - val_loss: 1.5617\n",
      "\n",
      "Epoch 00084: saving model to cache/TrainedOn10_2_5-084-1.5617.hdf5\n",
      "Epoch 85/100\n",
      "94831/94831 [==============================] - 54s 571us/step - loss: 1.4542 - val_loss: 1.5387\n",
      "\n",
      "Epoch 00085: saving model to cache/TrainedOn10_2_5-085-1.5387.hdf5\n",
      "Epoch 86/100\n",
      "94831/94831 [==============================] - 54s 574us/step - loss: 1.4529 - val_loss: 1.5527\n",
      "\n",
      "Epoch 00086: saving model to cache/TrainedOn10_2_5-086-1.5527.hdf5\n",
      "Epoch 87/100\n",
      "94831/94831 [==============================] - 56s 594us/step - loss: 1.4490 - val_loss: 1.5702\n",
      "\n",
      "Epoch 00087: saving model to cache/TrainedOn10_2_5-087-1.5702.hdf5\n",
      "Epoch 88/100\n",
      "94831/94831 [==============================] - 57s 604us/step - loss: 1.4485 - val_loss: 1.5552\n",
      "\n",
      "Epoch 00088: saving model to cache/TrainedOn10_2_5-088-1.5552.hdf5\n",
      "Epoch 89/100\n",
      "94831/94831 [==============================] - 54s 566us/step - loss: 1.4447 - val_loss: 1.5789\n",
      "\n",
      "Epoch 00089: saving model to cache/TrainedOn10_2_5-089-1.5789.hdf5\n",
      "Epoch 90/100\n",
      "94831/94831 [==============================] - 81s 849us/step - loss: 1.4440 - val_loss: 1.5896\n",
      "\n",
      "Epoch 00090: saving model to cache/TrainedOn10_2_5-090-1.5896.hdf5\n",
      "Epoch 91/100\n",
      "94831/94831 [==============================] - 53s 559us/step - loss: 1.4391 - val_loss: 1.5638\n",
      "\n",
      "Epoch 00091: saving model to cache/TrainedOn10_2_5-091-1.5638.hdf5\n",
      "Epoch 92/100\n",
      "94831/94831 [==============================] - 54s 566us/step - loss: 1.4352 - val_loss: 1.5920\n",
      "\n",
      "Epoch 00092: saving model to cache/TrainedOn10_2_5-092-1.5920.hdf5\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94831/94831 [==============================] - 54s 568us/step - loss: 1.4362 - val_loss: 1.5548\n",
      "\n",
      "Epoch 00093: saving model to cache/TrainedOn10_2_5-093-1.5548.hdf5\n",
      "Epoch 94/100\n",
      "94831/94831 [==============================] - 87s 916us/step - loss: 1.4369 - val_loss: 1.5645\n",
      "\n",
      "Epoch 00094: saving model to cache/TrainedOn10_2_5-094-1.5645.hdf5\n",
      "Epoch 95/100\n",
      "94831/94831 [==============================] - 88s 930us/step - loss: 1.4316 - val_loss: 1.5844\n",
      "\n",
      "Epoch 00095: saving model to cache/TrainedOn10_2_5-095-1.5844.hdf5\n",
      "Epoch 96/100\n",
      "94831/94831 [==============================] - 94s 996us/step - loss: 1.4302 - val_loss: 1.5591\n",
      "\n",
      "Epoch 00096: saving model to cache/TrainedOn10_2_5-096-1.5591.hdf5\n",
      "Epoch 97/100\n",
      "94831/94831 [==============================] - 92s 974us/step - loss: 1.4280 - val_loss: 1.5759\n",
      "\n",
      "Epoch 00097: saving model to cache/TrainedOn10_2_5-097-1.5759.hdf5\n",
      "Epoch 98/100\n",
      "94831/94831 [==============================] - 92s 968us/step - loss: 1.4255 - val_loss: 1.5678\n",
      "\n",
      "Epoch 00098: saving model to cache/TrainedOn10_2_5-098-1.5678.hdf5\n",
      "Epoch 99/100\n",
      "94831/94831 [==============================] - 95s 999us/step - loss: 1.4226 - val_loss: 1.5801\n",
      "\n",
      "Epoch 00099: saving model to cache/TrainedOn10_2_5-099-1.5801.hdf5\n",
      "Epoch 100/100\n",
      "94831/94831 [==============================] - 87s 917us/step - loss: 1.4226 - val_loss: 1.5631\n",
      "\n",
      "Epoch 00100: saving model to cache/TrainedOn10_2_5-100-1.5631.hdf5\n"
     ]
    }
   ],
   "source": [
    "os.chdir('code')\n",
    "from utils import tf_haversine,get_clusters\n",
    "os.chdir('..')\n",
    "history = full_train(data,clusters,save_prefix='TrainedOn10_2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndReL2J0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22721dd8978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je regarde à quel point il est bon\n",
    "#Je load les weights du modèle pas la peine de réentraîner hehe\n",
    "start_new_session()\n",
    "model = create_model(data.metadata, clusters)\n",
    "#c'est là que je load les weights\n",
    "model.load_weights('cache\\TrainedOn10_2_5-100-1.5631.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Les prédictions sur l'ensemble de test de la compet (tout petit)\n",
    "test_predictions = model.predict(process_features(data.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4601464225973106"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('code')\n",
    "from utils import np_haversine\n",
    "os.chdir('..')\n",
    "np_haversine(test_predictions, data.test_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En s'entraînant que sur le dixième des données, on obtient une loss de 1.46 (km) sur le truc de test. C'est mieux que sur le blog... Soit j'ai mal copié un truc qui fait que ça marche mieux hahah, soit keras 2.x et meilleur que 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
